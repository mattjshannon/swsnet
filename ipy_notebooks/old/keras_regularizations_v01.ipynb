{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing keras regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from IPython.core.debugger import set_trace as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "\n",
    "# My modules\n",
    "from swsnet import helpers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_NN(features, labels, test_size):\n",
    "def run_NN(input_tuple):\n",
    "    \"\"\"Run a Keras NN for the purpose of examining the effect of training set size.\n",
    "    \n",
    "    Args:\n",
    "        features (ndarray): Array containing the spectra (fluxes).\n",
    "        labels (ndarray): Array containing the group labels for the spectra.\n",
    "        test_size (float): Fraction of test size relative to (test + training).\n",
    "        \n",
    "    Returns:\n",
    "        test_size (float): Input test_size, just a sanity check!\n",
    "        accuracy (float): Accuracy of this neural net when applied to the test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    features, labels, test_size = input_tuple\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(features, labels, test_size=test_size, random_state = 42)\n",
    "    \n",
    "    # Sequential model, 7 classes of output.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', input_dim=359))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "    # Early stopping condition.\n",
    "    callback = [tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0)]\n",
    "\n",
    "    # Recompile model and fit.\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "#     model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, callbacks=callback, verbose=False)\n",
    "\n",
    "#     # Summary\n",
    "#     model.summary()\n",
    "\n",
    "    # Check accuracy.\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "#     print('Test loss:', score[0])\n",
    "#     print('Test accuracy:', score[1])\n",
    "\n",
    "    return test_size, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset: ISO-SWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed directories\n",
    "base_dir = '../data/isosws_atlas/'\n",
    "\n",
    "# Pickles containing our spectra in the form of pandas dataframes:\n",
    "spec_dir = base_dir + 'spectra/'\n",
    "spec_files = np.sort(glob.glob(spec_dir + '*.pkl'))\n",
    "\n",
    "# Metadata pickle (pd.dataframe). Note each entry contains a pointer to the corresponding spectrum pickle.\n",
    "metadata = base_dir + 'metadata.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels ('group'):\n",
    "\n",
    "1. Naked stars\n",
    "2. Stars with dust\n",
    "3. Warm, dusty objects\n",
    "4. Cool, dusty objects\n",
    "5. Very red objects\n",
    "6. Continuum-free objects but having emission lines\n",
    "7. Flux-free and/or fatally flawed spectra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B., these are shifted down by 1 in the labels (to span 0-6) for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 1: all data included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = helpers.load_data(base_dir=base_dir, metadata=metadata, clean=False, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1235, 359)\n",
      "(1235,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset 2: exclude group=7 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_clean, labels_clean = helpers.load_data(base_dir=base_dir, metadata=metadata, clean=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1058, 359)\n",
      "(1058,)\n"
     ]
    }
   ],
   "source": [
    "print(features_clean.shape)\n",
    "print(labels_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NN_l2(l2norm=0.01):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state = 42)\n",
    "\n",
    "    # Sequential model, 7 classes of output.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2norm), input_dim=359))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2norm)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2norm)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2norm)))\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "    # Early stopping condition.\n",
    "    callback = [tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0)]\n",
    "\n",
    "    # Recompile model and fit.\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    #     model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, callbacks=callback, verbose=False)\n",
    "\n",
    "    # Check accuracy.\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    print(\"L2 norm, accuracy: \", l2norm, accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm, accuracy:  1e-07 0.7574124003677677\n",
      "L2 norm, accuracy:  1e-06 0.7708894870673229\n",
      "L2 norm, accuracy:  1e-05 0.7169811323967905\n",
      "L2 norm, accuracy:  0.0001 0.7412398913799914\n",
      "L2 norm, accuracy:  0.001 0.7358490569250924\n",
      "L2 norm, accuracy:  0.01 0.7223719687796024\n",
      "L2 norm, accuracy:  0.1 0.5606468989842665\n",
      "L2 norm, accuracy:  1.0 0.3584905665197141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7574124003677677,\n",
       " 0.7708894870673229,\n",
       " 0.7169811323967905,\n",
       " 0.7412398913799914,\n",
       " 0.7358490569250924,\n",
       " 0.7223719687796024,\n",
       " 0.5606468989842665,\n",
       " 0.3584905665197141]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[run_NN_l2(float(10)**x) for x in np.arange(-7, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NN_l1(l1norm=0.01):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state = 42)\n",
    "\n",
    "    # Sequential model, 7 classes of output.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1(l1norm), input_dim=359))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1(l1norm)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1(l1norm)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1(l1norm)))\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "    # Early stopping condition.\n",
    "    callback = [tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0)]\n",
    "\n",
    "    # Recompile model and fit.\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    #     model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, callbacks=callback, verbose=False)\n",
    "\n",
    "    # Check accuracy.\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    print(\"L1 norm, accuracy: \", l1norm, accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm, accuracy:  1e-07 0.7088948782242211\n",
      "L1 norm, accuracy:  1e-06 0.7385444739115528\n",
      "L1 norm, accuracy:  1e-05 0.7439353091697487\n",
      "L1 norm, accuracy:  0.0001 0.733153639135335\n",
      "L1 norm, accuracy:  0.001 0.7223719687796024\n",
      "L1 norm, accuracy:  0.01 0.4609164418878581\n",
      "L1 norm, accuracy:  0.1 0.20485175210189305\n",
      "L1 norm, accuracy:  1.0 0.20485175210189305\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7088948782242211,\n",
       " 0.7385444739115528,\n",
       " 0.7439353091697487,\n",
       " 0.733153639135335,\n",
       " 0.7223719687796024,\n",
       " 0.4609164418878581,\n",
       " 0.20485175210189305,\n",
       " 0.20485175210189305]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[run_NN_l1(float(10)**x) for x in np.arange(-7, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NN_l1_l2(penalty=0.01):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state = 42)\n",
    "\n",
    "    # Sequential model, 7 classes of output.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=penalty, l2=penalty), input_dim=359))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=penalty, l2=penalty)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=penalty, l2=penalty)))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=penalty, l2=penalty)))\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "    # Early stopping condition.\n",
    "    callback = [tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0)]\n",
    "\n",
    "    # Recompile model and fit.\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    #     model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, callbacks=callback, verbose=False)\n",
    "\n",
    "    # Check accuracy.\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    print(\"L1_L2 norm, accuracy: \", penalty, accuracy)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1_L2 norm, accuracy:  1e-07 0.7547169825780102\n",
      "L1_L2 norm, accuracy:  1e-06 0.7601078178362063\n",
      "L1_L2 norm, accuracy:  1e-05 0.7142857138037361\n",
      "L1_L2 norm, accuracy:  0.0001 0.7385444735902339\n",
      "L1_L2 norm, accuracy:  0.001 0.6981132089931046\n",
      "L1_L2 norm, accuracy:  0.01 0.3450134776512568\n",
      "L1_L2 norm, accuracy:  0.1 0.35849056611806557\n",
      "L1_L2 norm, accuracy:  1.0 0.167115902985042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7547169825780102,\n",
       " 0.7601078178362063,\n",
       " 0.7142857138037361,\n",
       " 0.7385444735902339,\n",
       " 0.6981132089931046,\n",
       " 0.3450134776512568,\n",
       " 0.35849056611806557,\n",
       " 0.167115902985042]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[run_NN_l1_l2(penalty=float(10)**x) for x in np.arange(-7, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_NN_reg(kernel_regularizer=keras.regularizers.l2(0.01)):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(features, labels, test_size=0.3, random_state = 42)\n",
    "\n",
    "    # Sequential model, 7 classes of output.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer, input_dim=359))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=kernel_regularizer))\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "    # Early stopping condition.\n",
    "    callback = [tf.keras.callbacks.EarlyStopping(monitor='acc', patience=3, verbose=0)]\n",
    "\n",
    "    # Recompile model and fit.\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.0005),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    #     model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=False)\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, callbacks=callback, verbose=False)\n",
    "\n",
    "    # Check accuracy.\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    accuracy = score[1]\n",
    "    print(\"kernel_reg, constant, accuracy: \", kernel_regularizer, reg_constant, accuracy)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg_constant' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b10ef388d2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_NN_reg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-1dff8f7a5028>\u001b[0m in \u001b[0;36mrun_NN_reg\u001b[0;34m(kernel_regularizer)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kernel_reg, constant, accuracy: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_constant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reg_constant' is not defined"
     ]
    }
   ],
   "source": [
    "run_NN_reg(keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_NN_reg(keras.regularizers.l1(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
